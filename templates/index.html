<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
            transition: all 0.3s ease;
        }
        
        .personality-card.active {
            background: rgba(255,215,0,0.2);
            border: 2px solid #ffd700;
        }
        
        .personality-card.inactive {
            opacity: 0.6;
            background: rgba(255,255,255,0.05);
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Choose a personality to start conversation</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card" id="card-empathetic">
                <h3>Empathetic Friend</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Ready</div>
                <button class="personality-btn" id="btn-empathetic" onclick="togglePersonality('empathetic')">Start Conversation</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card" id="card-practical">
                <h3>Practical Coach</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Ready</div>
                <button class="personality-btn" id="btn-practical" onclick="togglePersonality('practical')">Start Conversation</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card" id="card-wise">
                <h3>Wise Mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Ready</div>
                <button class="personality-btn" id="btn-wise" onclick="togglePersonality('wise')">Start Conversation</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        let currentActivePersonality = null; // Track which personality is currently active
        let sharedMicrophoneStream = null; // Single shared microphone stream
        
        // Separate state for each personality
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioQueue: [],
                isPlayingAudio: false,
                prompt: "You are a warm, empathetic AI friend named 'The Empathetic Friend'. Listen actively, validate emotions, and provide emotional support. Be understanding, compassionate, and caring. Keep responses conversational and under 2 sentences.",
                name: "The Empathetic Friend"
            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioQueue: [],
                isPlayingAudio: false,
                prompt: "You are a practical, solution-focused AI coach named 'The Practical Coach'. Provide direct, actionable advice and help users solve problems efficiently. Be encouraging but concise and results-oriented. Keep responses brief and under 2 sentences.",
                name: "The Practical Coach"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioQueue: [],
                isPlayingAudio: false,
                prompt: "You are a wise, thoughtful AI mentor named 'The Wise Mentor'. Guide users through reflection and deeper thinking. Ask meaningful questions and share insights. Be thoughtful and philosophical but keep responses under 2 sentences.",
                name: "The Wise Mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('ðŸš€ Initializing...');
            initializeAudioContext();
            getApiKey();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('ðŸ”Š Audio context initialized');
            } catch (error) {
                console.error('âŒ Audio context error:', error);
            }
        }

        function getApiKey() {
            // For demo purposes, using a placeholder
            // Replace this with your actual API key fetching logic
            apiKey = "your-hume-api-key-here";
            updateGlobalStatus('Ready! Click any personality to start conversation');
            console.log('âœ… API key loaded successfully');
            
            /* Uncomment and modify this for actual API key fetching:
            fetch('/api/hume-key')
                .then(response => response.json())
                .then(data => {
                    if (data.api_key) {
                        apiKey = data.api_key;
                        updateGlobalStatus('Ready! Click any personality to start conversation');
                        console.log('âœ… API key loaded successfully');
                    } else {
                        throw new Error('No API key received');
                    }
                })
                .catch(error => {
                    console.error('âŒ Error getting API key:', error);
                    updateGlobalStatus('Error: Could not get API key');
                });
            */
        }

        function togglePersonality(personalityType) {
            const personality = personalities[personalityType];
            
            if (!personality.isConnected) {
                // Stop any currently active personality first
                if (currentActivePersonality && currentActivePersonality !== personalityType) {
                    stopPersonalityConversation(currentActivePersonality);
                }
                startPersonalityConversation(personalityType);
            } else {
                stopPersonalityConversation(personalityType);
            }
        }

        async function initializeMicrophone() {
            if (!sharedMicrophoneStream) {
                try {
                    sharedMicrophoneStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });
                    console.log('ðŸŽ™ï¸ Shared microphone stream initialized');
                } catch (error) {
                    console.error('âŒ Microphone access error:', error);
                    throw error;
                }
            }
            return sharedMicrophoneStream;
        }

        function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);
            updatePersonalityCardState(personalityType, 'connecting');

            try {
                // Connect to Hume EVI WebSocket
                const wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`âœ… ${personalityType} connected to Hume EVI`);
                    updatePersonalityStatus(personalityType, 'Connected! Starting microphone...');
                    
                    // Send personality prompt
                    const systemMessage = {
                        type: 'session_settings',
                        system_prompt: personality.prompt + " The user's name is User. Greet them warmly and introduce yourself as " + personality.name + ".",
                        language: 'en'
                    };
                    personality.socket.send(JSON.stringify(systemMessage));
                    
                    initializeMicrophone()
                        .then(() => startPersonalityMicrophone(personalityType))
                        .catch(error => {
                            console.error(`âŒ ${personalityType} microphone error:`, error);
                            updatePersonalityStatus(personalityType, 'Microphone access denied');
                            if (personality.socket) personality.socket.close();
                        });
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`ðŸ“¨ ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        addToPersonalityTranscript(personalityType, 'AI: ' + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                    } else if (data.type === 'audio_output') {
                        console.log(`ðŸ”Š ${personalityType} received audio chunk`);
                        playPersonalityAudio(personalityType, data.data);
                    } else if (data.type === 'assistant_end') {
                        console.log(`ðŸŽµ ${personalityType} assistant finished`);
                        // Don't change state here - let audio finish naturally
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop playing audio
                        stopPersonalityAudio(personalityType);
                        updatePersonalityStatus(personalityType, 'Listening...');
                        updatePersonalitySun(personalityType, 'listening');
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`âŒ ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalityCardState(personalityType, 'inactive');
                };

                personality.socket.onclose = function() {
                    console.log(`ðŸ”Œ ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, 'idle');
                    updatePersonalityCardState(personalityType, 'inactive');
                    personality.isConnected = false;
                    
                    if (currentActivePersonality === personalityType) {
                        currentActivePersonality = null;
                    }
                };

            } catch (error) {
                console.error(`âŒ Error starting ${personalityType} conversation:`, error);
                updatePersonalityStatus(personalityType, 'Error starting conversation');
                updatePersonalityButton(personalityType, 'Start Conversation', false);
                updatePersonalityCardState(personalityType, 'inactive');
            }
        }

        function startPersonalityMicrophone(personalityType) {
            const personality = personalities[personalityType];
            
            console.log(`ðŸŽ™ï¸ ${personalityType} microphone access granted`);
            
            personality.recorder = new MediaRecorder(sharedMicrophoneStream, {
                mimeType: 'audio/webm;codecs=opus'
            });

            personality.recorder.ondataavailable = function(event) {
                // Only send audio if this personality is currently active
                if (currentActivePersonality === personalityType && 
                    event.data.size > 0 && 
                    personality.socket && 
                    personality.socket.readyState === WebSocket.OPEN) {
                    const reader = new FileReader();
                    reader.onloadend = function() {
                        const base64Audio = reader.result.split(',')[1];
                        personality.socket.send(JSON.stringify({
                            type: 'audio_input',
                            data: base64Audio
                        }));
                    };
                    reader.readAsDataURL(event.data);
                }
            };

            personality.recorder.start(100); // Send audio every 100ms
            
            personality.isConnected = true;
            currentActivePersonality = personalityType; // Set as active personality
            
            updatePersonalityStatus(personalityType, 'Listening...');
            updatePersonalitySun(personalityType, 'listening');
            updatePersonalityButton(personalityType, 'Stop Conversation', false);
            updatePersonalityCardState(personalityType, 'active');
            updateGlobalStatus(`Now talking with ${personality.name}`);
            
            console.log(`ðŸŽ¤ ${personalityType} recording started and set as active`);
        }

        function playPersonalityAudio(personalityType, audioData) {
            // Only play audio if this personality is currently active
            if (currentActivePersonality !== personalityType) {
                console.log(`ðŸ”‡ ${personalityType} audio ignored (not active personality)`);
                return;
            }
            
            const personality = personalities[personalityType];
            
            // Add to queue
            personality.audioQueue.push(audioData);
            console.log(`ðŸ“¦ ${personalityType} queued audio chunk (queue: ${personality.audioQueue.length})`);
            
            // Start playing if not already playing
            if (!personality.isPlayingAudio) {
                playNextAudioChunk(personalityType);
            }
        }

        function playNextAudioChunk(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioQueue.length === 0) {
                console.log(`ðŸ”‡ ${personalityType} audio queue empty - returning to listening`);
                personality.isPlayingAudio = false;
                if (currentActivePersonality === personalityType) {
                    updatePersonalityStatus(personalityType, 'Listening...');
                    updatePersonalitySun(personalityType, 'listening');
                }
                return;
            }
            
            const audioData = personality.audioQueue.shift();
            console.log(`ðŸ”Š ${personalityType} playing audio chunk (${personality.audioQueue.length} remaining)`);
            
            try {
                // Stop any current audio first
                if (personality.currentAudio) {
                    personality.currentAudio.pause();
                    personality.currentAudio = null;
                }
                
                // Decode base64 audio
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                const audioBlob = new Blob([bytes], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                
                personality.currentAudio = new Audio();
                personality.isPlayingAudio = true;
                
                personality.currentAudio.oncanplaythrough = function() {
                    console.log(`ðŸ”Š ${personalityType} audio chunk ready to play`);
                    personality.currentAudio.play().catch(error => {
                        console.error(`âŒ ${personalityType} audio play error:`, error);
                        // Try next chunk
                        setTimeout(() => playNextAudioChunk(personalityType), 100);
                    });
                };
                
                personality.currentAudio.onplay = function() {
                    console.log(`ðŸ”Š ${personalityType} audio chunk playback started`);
                };
                
                personality.currentAudio.onended = function() {
                    console.log(`ðŸ”Š ${personalityType} audio chunk ended - playing next`);
                    URL.revokeObjectURL(audioUrl);
                    personality.currentAudio = null;
                    // Play next chunk immediately
                    setTimeout(() => playNextAudioChunk(personalityType), 50);
                };
                
                personality.currentAudio.onerror = function(error) {
                    console.error(`âŒ ${personalityType} audio chunk error:`, error);
                    URL.revokeObjectURL(audioUrl);
                    personality.currentAudio = null;
                    // Try next chunk
                    setTimeout(() => playNextAudioChunk(personalityType), 100);
                };
                
                personality.currentAudio.src = audioUrl;
                personality.currentAudio.load();
                
            } catch (error) {
                console.error(`âŒ Error playing ${personalityType} audio chunk:`, error);
                // Try next chunk
                setTimeout(() => playNextAudioChunk(personalityType), 100);
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            // Clear queue
            personality.audioQueue = [];
            personality.isPlayingAudio = false;
            
            if (personality.currentAudio) {
                personality.currentAudio.pause();
                personality.currentAudio.currentTime = 0;
                personality.currentAudio = null;
                console.log(`ðŸ”‡ ${personalityType} audio stopped and queue cleared`);
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            console.log(`ðŸ”š Stopping ${personalityType} conversation`);
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder = null;
            }
            
            stopPersonalityAudio(personalityType);
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            personality.isConnected = false;
            updatePersonalityStatus(personalityType, 'Conversation stopped');
            updatePersonalitySun(personalityType, 'idle');
            updatePersonalityButton(personalityType, 'Start Conversation', false);
            updatePersonalityCardState(personalityType, 'inactive');
            
            if (currentActivePersonality === personalityType) {
                currentActivePersonality = null;
                updateGlobalStatus('Choose a personality to start conversation');
            }
        }

        function stopAllConversations() {
            console.log('ðŸ”š Stopping all conversations');
            Object.keys(personalities).forEach(personalityType => {
                if (personalities[personalityType].isConnected) {
                    stopPersonalityConversation(personalityType);
                }
            });
            
            // Clean up shared microphone stream
            if (sharedMicrophoneStream) {
                sharedMicrophoneStream.getTracks().forEach(track => track.stop());
                sharedMicrophoneStream = null;
            }
            
            currentActivePersonality = null;
            updateGlobalStatus('All conversations stopped');
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
            console.log('ðŸ“Š Global Status:', message);
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
            console.log(`ðŸ“Š ${personalityType} Status:`, message);
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (personalities[personalityType].isConnected) {
                button.classList.add('active');
            } else {
                button.classList.remove('active');
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = 'sun';
            if (state !== 'idle') {
                sun.classList.add(state);
            }
        }

        function updatePersonalityCardState(personalityType, state) {
            const card = document.getElementById(`card-${personalityType}`);
            
            // Remove all state classes
            card.classList.remove('active', 'inactive');
            
            // Add appropriate state class
            if (state === 'active') {
                card.classList.add('active');
                // Make other cards inactive
                Object.keys(personalities).forEach(type => {
                    if (type !== personalityType) {
                        document.getElementById(`card-${type}`).classList.remove('active');
                        document.getElementById(`card-${type}`).classList.add('inactive');
                    }
                });
            } else if (state === 'inactive') {
                card.classList.add('inactive');
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        // Handle page unload
        window.addEventListener('beforeunload', function() {
            stopAllConversations();
        });

        // Handle user interaction for audio context
        document.addEventListener('click', function() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume();
                console.log('ðŸ”Š Audio context resumed');
            }
        });
    </script>
</body>
</html>


