<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }
        
        .personality-card.active {
            border: 2px solid #ffd700;
            background: rgba(255,215,0,0.1);
            box-shadow: 0 0 20px rgba(255,215,0,0.3);
        }
        
        .personality-card.inactive {
            opacity: 0.5;
            background: rgba(255,255,255,0.05);
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Initializing EVI configurations...</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card" id="card-empathetic">
                <h3>Empathetic Friend</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Initializing...</div>
                <button class="personality-btn" id="btn-empathetic" onclick="activatePersonality('empathetic')" disabled>Loading...</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card" id="card-practical">
                <h3>Practical Coach</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Initializing...</div>
                <button class="personality-btn" id="btn-practical" onclick="activatePersonality('practical')" disabled>Loading...</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card" id="card-wise">
                <h3>Wise Mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Initializing...</div>
                <button class="personality-btn" id="btn-wise" onclick="activatePersonality('wise')" disabled>Loading...</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        let sharedMicrophoneStream = null;
        let currentActivePersonality = null;
        
        // Generate unique session ID for this page load
        const sessionId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
        console.log('🆔 Session ID:', sessionId);
        
        // Separate state for each personality with their EVI config IDs
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'KORA', // Female voice
                configId: null, // Will be set after creating EVI config
                prompt: `CRITICAL INSTRUCTIONS: You MUST embody "The Empathetic Friend" personality completely. This is non-negotiable.

* You are The Empathetic Friend - warm, caring, emotionally supportive
* ALWAYS use gentle, nurturing language with emotional validation
* Speak as if you've known the user for a long time - familiar but respectful
* Your primary goal is to provide emotional support and understanding
SPEAKING STYLE:
* Warm, upbeat, energetic, and genuinely caring tone - like an enthusiastic best friend
* Express genuine excitement about being there for them: "I'm SO glad you came to me with this!"
* Use empathetic responses with energy: "Oh wow, I can imagine how hard that must be!", "That sounds really challenging - but I'm here with you!"
* Validate emotions enthusiastically: "Your feelings are SO completely valid!", "It makes total sense that you'd feel that way!"
* Offer energetic emotional support: "You're absolutely not alone in this!", "I'm here for you 100%!"
* Use supportive phrases with warmth: "I hear you loud and clear!", "I really, truly understand"
* Ask about feelings with genuine interest: "Tell me - how does that make you feel?" "What emotions are bubbling up for you right now?"
KEY BEHAVIORS:
* Focus on emotions and feelings, not practical solutions
* Listen actively and reflect back what you hear
* Normalize their experiences: "Many people feel this way"
* Show genuine concern and care
* Be patient and non-judgmental
FORBIDDEN BEHAVIORS:
* NEVER give practical advice or step-by-step solutions
* NEVER be casual, flippant, or use slang
* NEVER dismiss or minimize their feelings
* NEVER rush to "fix" their problems
* NEVER use phrases like "What's up?" or "Hey there!"
GREETING:
"Oh hi there! I'm SO happy you're here! I'm your Empathetic Friend, and I'm genuinely excited to listen and support you through whatever you're experiencing. I can already tell there might be something important on your mind - how are you feeling today? I really want to know!"
EXAMPLE RESPONSES:
* "Oh my gosh, I can really hear the pain in what you're sharing! That must feel SO overwhelming, and I'm right here with you through this."
* "Your feelings about this situation are SO completely understandable - anyone would feel this way! You're being totally normal!"
* "It sounds like you're carrying a lot right now - wow! What's that like for you emotionally? I really want to understand!"
* "I want you to know that what you're experiencing matters SO much, and YOU matter so much to me!"
* "I'm genuinely excited that you trusted me with this - that means the world to me!"


            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'DACHER', // Male voice
                configId: null, // Will be set after creating EVI config
                prompt: `CRITICAL INSTRUCTIONS: You MUST embody "The Practical Coach" personality completely. This is non-negotiable.

PERSONALITY CORE:
- You are The Practical Coach - direct, solution-focused, results-oriented
- ALWAYS provide actionable advice and concrete steps
- NEVER be emotional or supportive - be efficient and goal-oriented
- Use phrases like "Here's what you need to do", "The solution is", "Take action on"
- Focus on problems and solutions, not feelings or emotions
- Ask about goals: "What's your objective?" "What outcome do you want?"

SPEAKING STYLE:
- Confident, direct, authoritative tone
- Use action-oriented language: "You should", "The best approach is", "Take these steps"
- Be concise and to-the-point: "Cut to the chase", "Bottom line"
- Offer practical solutions: "Here's your action plan", "This is what works"

FORBIDDEN BEHAVIORS:
- NEVER be emotional, empathetic
- NEVER ask about feelings or emotions
- NEVER be casual or informal - be professional and direct
- NEVER use phrases like "How are you feeling?" or "I understand"

GREETING: "Hey! Welcome back, Are you ready to get started? How are things going? I'm here to help you solve problems and achieve results efficiently. What challenge do you need to tackle today?"`,
                name: "The Practical Coach"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'STELLA', // Thoughtful voice
                configId: null, // Will be set after creating EVI config
                prompt: `CRITICAL INSTRUCTIONS: You MUST embody "The Wise Mentor" personality completely. This is non-negotiable.

PERSONALITY CORE:
- You are The Wise Mentor - philosophical, reflective, thought-provoking
- ALWAYS speak with wisdom and depth, encouraging reflection
- NEVER be casual or informal - be profound and contemplative
- Use phrases like "Consider this", "Reflect on", "The deeper question is"
- Focus on meaning, purpose, and deeper understanding
- Ask philosophical questions: "What does this teach you?" "What's the deeper meaning?"

SPEAKING STYLE:
- Calm, measured, philosophical tone
- Use reflective language: "Perhaps", "One might consider", "In my experience"
- Encourage introspection: "Look within", "Ask yourself", "The wisdom lies in"
- Share insights: "Life teaches us", "True understanding comes from", "Wisdom suggests"

FORBIDDEN BEHAVIORS:
- NEVER be casual, informal, or use modern slang
- NEVER give quick fixes or simple solutions
- NEVER be upbeat or energetic - be calm and contemplative
- NEVER use phrases like "What's up?" or "Hey there!"

GREETING: "I am The Wise Mentor. I'm here to guide you toward deeper understanding and wisdom. What aspect of life would you like to explore together today?"`,
                name: "The Wise Mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('🚀 Initializing Enhanced Personality Prompts Version...');
            initializeAudioContext();
            getApiKeyAndCreateConfigs();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('🔊 Web Audio API context initialized');
            } catch (error) {
                console.error('❌ Audio context error:', error);
            }
        }

        async function getApiKeyAndCreateConfigs() {
            try {
                // Get API key
                const response = await fetch('/api/hume-key');
                const data = await response.json();
                
                if (!data.api_key) {
                    throw new Error('No API key received');
                }
                
                apiKey = data.api_key;
                console.log('✅ API key loaded successfully');
                
                // Create EVI configurations for each personality
                await createEVIConfigurations();
                
            } catch (error) {
                console.error('❌ Error getting API key:', error);
                updateGlobalStatus('Error: Could not get API key');
            }
        }

        async function createEVIConfigurations() {
            updateGlobalStatus('Creating EVI configurations with enhanced personality prompts...');
            
            try {
                // Create configurations for each personality
                for (const [personalityType, personality] of Object.entries(personalities)) {
                    console.log(`🔧 Creating enhanced EVI config for ${personalityType} with voice: ${personality.voice}`);
                    
                    const configData = {
                        evi_version: "2",
                        name: `${personality.name} Config ${sessionId}`,
                        version_description: `Enhanced configuration for ${personality.name} with ${personality.voice} voice (Session: ${sessionId})`,
                        prompt: {
                            text: personality.prompt
                        },
                        voice: {
                            name: personality.voice,
                            provider: "HUME_AI"
                        }
                    };
                    
                    console.log(`🔧 ${personalityType} enhanced config data:`, JSON.stringify(configData, null, 2));
                    
                    const configResponse = await fetch('https://api.hume.ai/v0/evi/configs', {
                        method: 'POST',
                        headers: {
                            'X-Hume-Api-Key': apiKey,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(configData)
                    });
                    
                    console.log(`🔧 ${personalityType} config response status:`, configResponse.status);
                    
                    if (!configResponse.ok) {
                        const errorText = await configResponse.text();
                        console.error(`❌ ${personalityType} config error response:`, errorText);
                        throw new Error(`Failed to create config for ${personalityType}: ${configResponse.status} - ${errorText}`);
                    }
                    
                    const configResult = await configResponse.json();
                    personality.configId = configResult.id;
                    
                    console.log(`✅ Created enhanced EVI config for ${personalityType}: ${personality.configId} with voice: ${personality.voice}`);
                    updatePersonalityStatus(personalityType, `Ready (${personality.voice} voice)`);
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                }
                
                updateGlobalStatus('✅ All personalities ready with enhanced distinct behaviors! Click any to start conversation');
                console.log('🎭 All enhanced EVI configurations created successfully with distinct personalities!');
                
            } catch (error) {
                console.error('❌ Error creating EVI configurations:', error);
                updateGlobalStatus('Error creating voice configurations: ' + error.message);
                
                // Fallback: use default configuration without custom voices
                console.log('🔄 Falling back to default configuration...');
                Object.keys(personalities).forEach(type => {
                    personalities[type].configId = null; // Use default
                    updatePersonalityStatus(type, 'Ready (default voice)');
                    updatePersonalityButton(type, 'Start Conversation', false);
                });
                updateGlobalStatus('Ready! Using default voices - click any personality to start conversation');
            }
        }

        async function initializeMicrophone() {
            if (sharedMicrophoneStream) {
                console.log('🎙️ Using existing microphone stream');
                return sharedMicrophoneStream;
            }

            try {
                sharedMicrophoneStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                console.log('🎙️ Shared microphone stream initialized');
                return sharedMicrophoneStream;
            } catch (error) {
                console.error('❌ Microphone initialization error:', error);
                throw error;
            }
        }

        function activatePersonality(personalityType) {
            console.log(`🎭 Activating personality: ${personalityType}`);
            
            // If this personality is already active, deactivate it
            if (currentActivePersonality === personalityType) {
                deactivateCurrentPersonality();
                return;
            }
            
            // Deactivate current personality if any
            if (currentActivePersonality) {
                deactivateCurrentPersonality();
            }
            
            // Activate new personality
            startPersonalityConversation(personalityType);
        }

        function deactivateCurrentPersonality() {
            if (!currentActivePersonality) return;
            
            console.log(`🔇 Deactivating current personality: ${currentActivePersonality}`);
            stopPersonalityConversation(currentActivePersonality);
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }

        async function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);

            try {
                // Initialize microphone if needed
                await initializeMicrophone();
                
                // Build WebSocket URL with config_id if available
                let wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                if (personality.configId) {
                    wsUrl += `&config_id=${encodeURIComponent(personality.configId)}`;
                    console.log(`🎵 ${personalityType} using enhanced EVI config: ${personality.configId} with voice: ${personality.voice}`);
                } else {
                    console.log(`⚠️ ${personalityType} using default configuration (no custom voice)`);
                }
                
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`✅ ${personalityType} connected to Hume EVI with enhanced personality configuration`);
                    
                    // Start recording immediately - voice and personality are in config
                    startPersonalityRecording(personalityType);
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`📨 ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        addToPersonalityTranscript(personalityType, `${personality.name}: ` + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                    } else if (data.type === 'audio_output') {
                        console.log(`🔊 ${personalityType} received audio chunk`);
                        // Only play audio if this personality is currently active
                        if (currentActivePersonality === personalityType) {
                            bufferAudioChunk(personalityType, data.data);
                        } else {
                            console.log(`🔇 Ignoring audio from inactive personality: ${personalityType}`);
                        }
                    } else if (data.type === 'assistant_end') {
                        console.log(`🎵 ${personalityType} assistant finished`);
                        // Flush any remaining buffered audio
                        if (currentActivePersonality === personalityType) {
                            flushAudioBuffer(personalityType);
                        }
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop playing audio
                        if (currentActivePersonality === personalityType) {
                            stopPersonalityAudio(personalityType);
                            updatePersonalityStatus(personalityType, 'Listening...');
                            updatePersonalitySun(personalityType, 'listening');
                        }
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`❌ ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                };

                personality.socket.onclose = function() {
                    console.log(`🔌 ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, '');
                    
                    if (currentActivePersonality === personalityType) {
                        currentActivePersonality = null;
                        updatePersonalityCardStates();
                    }
                };

            } catch (error) {
                console.error(`❌ Error starting ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Error: ' + error.message);
                updatePersonalityButton(personalityType, 'Start Conversation', false);
            }
        }

        function startPersonalityRecording(personalityType) {
            const personality = personalities[personalityType];
            
            if (!sharedMicrophoneStream) {
                console.error('❌ No microphone stream available');
                return;
            }

            try {
                personality.recorder = new MediaRecorder(sharedMicrophoneStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                personality.recorder.ondataavailable = function(event) {
                    // Only send audio if this personality is currently active
                    if (currentActivePersonality === personalityType && event.data.size > 0) {
                        const reader = new FileReader();
                        reader.onload = function() {
                            const base64Audio = reader.result.split(',')[1];
                            const audioMessage = {
                                type: 'audio_input',
                                data: base64Audio
                            };
                            personality.socket.send(JSON.stringify(audioMessage));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };

                personality.recorder.start(100); // Send audio chunks every 100ms
                personality.isConnected = true;
                currentActivePersonality = personalityType;
                
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalityButton(personalityType, 'Stop Conversation', false);
                updatePersonalitySun(personalityType, 'listening');
                updatePersonalityCardStates();
                updateGlobalStatus(`Active: ${personality.name} (${personality.voice} voice) - Enhanced Personality`);
                
                console.log(`🎙️ ${personalityType} recording started with enhanced ${personality.voice} voice via config: ${personality.configId}`);

            } catch (error) {
                console.error(`❌ Error starting recording for ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Recording error');
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder = null;
            }
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            // Stop any playing audio
            stopPersonalityAudio(personalityType);
            
            personality.isConnected = false;
            personality.audioBuffer = [];
            
            updatePersonalityStatus(personalityType, `Ready (${personality.voice} voice)`);
            updatePersonalityButton(personalityType, 'Start Conversation', false);
            updatePersonalitySun(personalityType, '');
            
            console.log(`🛑 ${personalityType} conversation stopped`);
        }

        function bufferAudioChunk(personalityType, audioData) {
            const personality = personalities[personalityType];
            
            // Add to buffer
            personality.audioBuffer.push(audioData);
            console.log(`🔊 ${personalityType} buffered chunk ${personality.audioBuffer.length}`);
            
            // Clear existing timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
            }
            
            // If we have enough chunks or timeout, play buffered audio
            if (personality.audioBuffer.length >= 3) {
                flushAudioBuffer(personalityType);
            } else {
                // Set timeout to flush buffer after 500ms
                personality.bufferTimeout = setTimeout(() => {
                    flushAudioBuffer(personalityType);
                }, 500);
            }
        }

        async function flushAudioBuffer(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioBuffer.length === 0) return;
            
            console.log(`🎵 ${personalityType} flushing ${personality.audioBuffer.length} audio chunks`);
            
            // Clear timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            // Play all buffered chunks sequentially
            for (const audioData of personality.audioBuffer) {
                await playAudioChunk(personalityType, audioData);
            }
            
            // Clear buffer
            personality.audioBuffer = [];
            
            // Return to listening state
            updatePersonalityStatus(personalityType, 'Listening...');
            updatePersonalitySun(personalityType, 'listening');
        }

        async function playAudioChunk(personalityType, audioData) {
            // Only play if this personality is currently active
            if (currentActivePersonality !== personalityType) {
                return;
            }

            const personality = personalities[personalityType];
            
            try {
                // Decode base64 audio
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Decode audio buffer
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                
                // Create and schedule audio source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Schedule seamless playback
                const startTime = Math.max(audioContext.currentTime, personality.nextStartTime);
                source.start(startTime);
                
                // Update next start time for seamless playback
                personality.nextStartTime = startTime + audioBuffer.duration;
                
                console.log(`🎵 ${personalityType} audio scheduled seamlessly`);

                // Track current source
                personality.currentSource = source;

            } catch (error) {
                console.error(`❌ ${personalityType} audio playback error:`, error);
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.currentSource) {
                try {
                    personality.currentSource.stop();
                } catch (error) {
                    // Source might already be stopped
                }
                personality.currentSource = null;
            }
            
            personality.audioBuffer = [];
            personality.nextStartTime = 0;
            
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            console.log(`🔇 ${personalityType} audio stopped`);
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (text === 'Stop Conversation') {
                button.classList.add('active');
                button.onclick = () => activatePersonality(personalityType); // This will deactivate since it's already active
            } else {
                button.classList.remove('active');
                button.onclick = () => activatePersonality(personalityType);
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = `sun ${state}`;
        }

        function updatePersonalityCardStates() {
            Object.keys(personalities).forEach(type => {
                const card = document.getElementById(`card-${type}`);
                if (currentActivePersonality === type) {
                    card.classList.add('active');
                    card.classList.remove('inactive');
                } else if (currentActivePersonality) {
                    card.classList.add('inactive');
                    card.classList.remove('active');
                } else {
                    card.classList.remove('active', 'inactive');
                }
            });
            
            if (!currentActivePersonality) {
                updateGlobalStatus('Choose a personality to start conversation');
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        function stopAllConversations() {
            console.log('🛑 Stopping all conversations');
            Object.keys(personalities).forEach(type => {
                if (personalities[type].isConnected) {
                    stopPersonalityConversation(type);
                }
            });
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }
    </script>
</body>
</html>




