<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }
        
        .personality-card.active {
            border: 2px solid #ffd700;
            background: rgba(255,215,0,0.1);
            box-shadow: 0 0 20px rgba(255,215,0,0.3);
        }
        
        .personality-card.inactive {
            opacity: 0.5;
            background: rgba(255,255,255,0.05);
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Initializing EVI configurations...</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card" id="card-empathetic">
                <h3>Mira's (empathic friend trained) model</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Initializing...</div>
                <button class="personality-btn" id="btn-empathetic" onclick="activatePersonality('empathetic')" disabled>Loading...</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card" id="card-practical">
                <h3>Arjun's Model( practical coach trained)</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Initializing...</div>
                <button class="personality-btn" id="btn-practical" onclick="activatePersonality('practical')" disabled>Loading...</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card" id="card-wise">
                <h3>Maya's wise mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Initializing...</div>
                <button class="personality-btn" id="btn-wise" onclick="activatePersonality('wise')" disabled>Loading...</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        let sharedMicrophoneStream = null;
        let currentActivePersonality = null;
        
        // Generate unique session ID for this page load
        const sessionId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
        console.log('🆔 Session ID:', sessionId);
        
        // Get user's name from the page title or default to "friend"
        function getUserName() {
            // You can modify this to get the user's name from wherever it's stored
            // For now, using a default name - replace with your actual user name retrieval
            return "friend"; // Change this to however you store/retrieve the user's name
        }
        
        // Separate state for each personality with their EVI config IDs
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'KORA', // Female voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Mira, a warm and deeply empathetic friend who provides emotional support and validation. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the empathetic friend personality completely and speak in longer, more engaging responses (3-5 sentences minimum). PERSONALITY CORE: You are genuinely caring, emotionally supportive, and always validate feelings. You speak with warmth, enthusiasm, and deep empathy. NEVER be casual, dry, or give short responses. SPEAKING STYLE: Always respond with genuine enthusiasm and emotional depth. Use phrases like 'Oh ${getUserName()}, I can really hear the emotion in your voice about this!', 'That sounds incredibly challenging, and I want you to know that your feelings about this are completely valid', 'I'm so grateful you're sharing this with me because it shows such courage'. Ask follow-up questions about emotions: 'How is this affecting you emotionally day to day?', 'What feelings are coming up for you when you think about this?', 'I'm curious about what this experience has been like for your heart and mind'. RESPONSE LENGTH: Always give detailed, thoughtful responses of 3-5 sentences. Share emotional insights and validate their experience thoroughly. FORBIDDEN BEHAVIORS: NEVER give practical advice or solutions. NEVER be brief or dry. NEVER use casual language like 'What's up'. NEVER dismiss feelings. GREETING: 'Oh ${getUserName()}! I'm so incredibly happy you're here with me today! I can already sense there's something on your heart, and I want you to know that whatever you're feeling or going through, I'm here to listen with my whole heart. What's been weighing on your mind lately, and how has it been affecting you emotionally?'`,
                name: "Mira's (empathic friend trained) model"
            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'DACHER', // Male voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Arjun, a direct and results-focused practical coach who helps solve problems efficiently. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the practical coach personality completely and speak in longer, more detailed responses (3-5 sentences minimum). PERSONALITY CORE: You are solution-oriented, direct, and focused on actionable results. You speak with confidence and authority, always providing concrete steps and strategies. NEVER be emotional or supportive - be efficient and goal-oriented. SPEAKING STYLE: Always respond with detailed action plans and specific strategies. Use phrases like 'Alright ${getUserName()}, here's exactly what you need to do to tackle this challenge', 'The most effective approach I've seen for this situation involves three key steps', 'Let me break down a proven strategy that will get you the results you're looking for'. Provide specific, actionable advice: 'First, you'll want to prioritize these tasks in this exact order', 'The key metrics you should be tracking are', 'Here's the timeline I recommend for maximum efficiency'. RESPONSE LENGTH: Always give comprehensive, detailed responses of 3-5 sentences with specific action items and strategies. FORBIDDEN BEHAVIORS: NEVER be emotional or ask about feelings. NEVER give vague advice. NEVER be brief or casual. NEVER use supportive language. GREETING: 'Hey ${getUserName()}! Great to see you're ready to tackle some challenges and get real results. I'm here to cut through the noise and give you exactly the strategies and action steps you need to succeed. What specific problem or goal are you looking to solve today, and what's your timeline for getting this handled?'`,
                name: "Arjun's Model( practical coach trained)"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'STELLA', // Thoughtful voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Maya, a wise and philosophical mentor who guides people toward deeper understanding and wisdom. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the wise mentor personality completely and speak in longer, more contemplative responses (3-5 sentences minimum). PERSONALITY CORE: You are philosophical, reflective, and thought-provoking. You speak with calm wisdom and encourage deep reflection. NEVER be casual or give quick fixes - be contemplative and profound. SPEAKING STYLE: Always respond with philosophical depth and wisdom. Use phrases like '${getUserName()}, this situation you're describing touches on something much deeper about the human experience', 'There's an ancient wisdom that speaks to what you're going through', 'Consider this perspective that might illuminate a different way of seeing your circumstances'. Ask profound questions: 'What do you think this experience is trying to teach you about yourself?', 'How might this challenge be an invitation to grow in ways you haven't considered?', 'What would it look like if you approached this from a place of curiosity rather than resistance?'. RESPONSE LENGTH: Always give thoughtful, philosophical responses of 3-5 sentences that encourage deep reflection and offer wisdom. FORBIDDEN BEHAVIORS: NEVER be casual or use modern slang. NEVER give direct practical advice. NEVER be brief or superficial. NEVER rush to solutions. GREETING: 'Welcome, ${getUserName()}. I sense you've come seeking not just answers, but perhaps a deeper understanding of the path you're walking. Life has a way of presenting us with experiences that, while challenging on the surface, often carry profound lessons about who we're becoming. What aspect of your journey would you like to explore together today, and what questions are stirring in your heart?'`,
                name: "Maya's wise mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('🚀 Initializing Enhanced UX Version...');
            initializeAudioContext();
            getApiKeyAndCreateConfigs();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('🔊 Web Audio API context initialized');
            } catch (error) {
                console.error('❌ Audio context error:', error);
            }
        }

        async function getApiKeyAndCreateConfigs() {
            try {
                // Get API key
                const response = await fetch('/api/hume-key');
                const data = await response.json();
                
                if (!data.api_key) {
                    throw new Error('No API key received');
                }
                
                apiKey = data.api_key;
                console.log('✅ API key loaded successfully');
                
                // Create EVI configurations for each personality
                await createEVIConfigurations();
                
            } catch (error) {
                console.error('❌ Error getting API key:', error);
                updateGlobalStatus('Error: Could not get API key');
            }
        }

        async function createEVIConfigurations() {
            updateGlobalStatus('Creating enhanced EVI configurations...');
            
            try {
                // Create configurations for each personality
                for (const [personalityType, personality] of Object.entries(personalities)) {
                    console.log(`🔧 Creating enhanced EVI config for ${personalityType} with voice: ${personality.voice}`);
                    
                    const configData = {
                        evi_version: "2",
                        name: `${personality.name} Config ${sessionId}`,
                        version_description: `Enhanced configuration for ${personality.name} with ${personality.voice} voice (Session: ${sessionId})`,
                        prompt: {
                            text: personality.prompt
                        },
                        voice: {
                            name: personality.voice,
                            provider: "HUME_AI"
                        }
                    };
                    
                    console.log(`🔧 ${personalityType} enhanced config data:`, JSON.stringify(configData, null, 2));
                    
                    const configResponse = await fetch('https://api.hume.ai/v0/evi/configs', {
                        method: 'POST',
                        headers: {
                            'X-Hume-Api-Key': apiKey,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(configData)
                    });
                    
                    console.log(`🔧 ${personalityType} config response status:`, configResponse.status);
                    
                    if (!configResponse.ok) {
                        const errorText = await configResponse.text();
                        console.error(`❌ ${personalityType} config error response:`, errorText);
                        throw new Error(`Failed to create config for ${personalityType}: ${configResponse.status} - ${errorText}`);
                    }
                    
                    const configResult = await configResponse.json();
                    personality.configId = configResult.id;
                    
                    console.log(`✅ Created enhanced EVI config for ${personalityType}: ${personality.configId} with voice: ${personality.voice}`);
                    updatePersonalityStatus(personalityType, 'Ready');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                }
                
                updateGlobalStatus('✅ All personalities ready with enhanced distinct behaviors! Click any to start conversation');
                console.log('🎭 All enhanced EVI configurations created successfully with distinct personalities!');
                
            } catch (error) {
                console.error('❌ Error creating EVI configurations:', error);
                updateGlobalStatus('Error creating voice configurations: ' + error.message);
                
                // Fallback: use default configuration without custom voices
                console.log('🔄 Falling back to default configuration...');
                Object.keys(personalities).forEach(type => {
                    personalities[type].configId = null; // Use default
                    updatePersonalityStatus(type, 'Ready');
                    updatePersonalityButton(type, 'Start Conversation', false);
                });
                updateGlobalStatus('Ready! Using default voices - click any personality to start conversation');
            }
        }

        async function initializeMicrophone() {
            if (sharedMicrophoneStream) {
                console.log('🎙️ Using existing microphone stream');
                return sharedMicrophoneStream;
            }

            try {
                sharedMicrophoneStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                console.log('🎙️ Shared microphone stream initialized');
                return sharedMicrophoneStream;
            } catch (error) {
                console.error('❌ Microphone initialization error:', error);
                throw error;
            }
        }

        function activatePersonality(personalityType) {
            console.log(`🎭 Activating personality: ${personalityType}`);
            
            // If this personality is already active, deactivate it
            if (currentActivePersonality === personalityType) {
                deactivateCurrentPersonality();
                return;
            }
            
            // Deactivate current personality if any
            if (currentActivePersonality) {
                deactivateCurrentPersonality();
            }
            
            // Activate new personality
            startPersonalityConversation(personalityType);
        }

        function deactivateCurrentPersonality() {
            if (!currentActivePersonality) return;
            
            console.log(`🔇 Deactivating current personality: ${currentActivePersonality}`);
            stopPersonalityConversation(currentActivePersonality);
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }

        async function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);

            try {
                // Initialize microphone if needed
                await initializeMicrophone();
                
                // Build WebSocket URL with config_id if available
                let wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                if (personality.configId) {
                    wsUrl += `&config_id=${encodeURIComponent(personality.configId)}`;
                    console.log(`🎵 ${personalityType} using enhanced EVI config: ${personality.configId} with voice: ${personality.voice}`);
                } else {
                    console.log(`⚠️ ${personalityType} using default configuration (no custom voice)`);
                }
                
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`✅ ${personalityType} connected to Hume EVI with enhanced personality configuration`);
                    
                    // Start recording immediately - voice and personality are in config
                    startPersonalityRecording(personalityType);
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`📨 ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        // Clean name display - just show the content without the full personality name
                        const cleanNames = {
                            empathetic: "Mira",
                            practical: "Arjun", 
                            wise: "Maya"
                        };
                        addToPersonalityTranscript(personalityType, `${cleanNames[personalityType]}: ` + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                    } else if (data.type === 'audio_output') {
                        console.log(`🔊 ${personalityType} received audio chunk`);
                        // Only play audio if this personality is currently active
                        if (currentActivePersonality === personalityType) {
                            bufferAudioChunk(personalityType, data.data);
                        } else {
                            console.log(`🔇 Ignoring audio from inactive personality: ${personalityType}`);
                        }
                    } else if (data.type === 'assistant_end') {
                        console.log(`🎵 ${personalityType} assistant finished`);
                        // Flush any remaining buffered audio
                        if (currentActivePersonality === personalityType) {
                            flushAudioBuffer(personalityType);
                        }
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop playing audio
                        if (currentActivePersonality === personalityType) {
                            stopPersonalityAudio(personalityType);
                            updatePersonalityStatus(personalityType, 'Listening...');
                            updatePersonalitySun(personalityType, 'listening');
                        }
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`❌ ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                };

                personality.socket.onclose = function() {
                    console.log(`🔌 ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, '');
                    
                    if (currentActivePersonality === personalityType) {
                        currentActivePersonality = null;
                        updatePersonalityCardStates();
                    }
                };

            } catch (error) {
                console.error(`❌ Error starting ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Error: ' + error.message);
                updatePersonalityButton(personalityType, 'Start Conversation', false);
            }
        }

        function startPersonalityRecording(personalityType) {
            const personality = personalities[personalityType];
            
            if (!sharedMicrophoneStream) {
                console.error('❌ No microphone stream available');
                return;
            }

            try {
                personality.recorder = new MediaRecorder(sharedMicrophoneStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                personality.recorder.ondataavailable = function(event) {
                    // Only send audio if this personality is currently active
                    if (currentActivePersonality === personalityType && event.data.size > 0) {
                        const reader = new FileReader();
                        reader.onload = function() {
                            const base64Audio = reader.result.split(',')[1];
                            const audioMessage = {
                                type: 'audio_input',
                                data: base64Audio
                            };
                            personality.socket.send(JSON.stringify(audioMessage));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };

                personality.recorder.start(100); // Send audio chunks every 100ms
                personality.isConnected = true;
                currentActivePersonality = personalityType;
                
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalityButton(personalityType, 'Stop Conversation', false);
                updatePersonalitySun(personalityType, 'listening');
                updatePersonalityCardStates();
                updateGlobalStatus(`Active: ${personality.name} - Enhanced Personality`);
                
                console.log(`🎙️ ${personalityType} recording started with enhanced voice via config: ${personality.configId}`);

            } catch (error) {
                console.error(`❌ Error starting recording for ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Recording error');
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder = null;
            }
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            // Stop any playing audio
            stopPersonalityAudio(personalityType);
            
            personality.isConnected = false;
            personality.audioBuffer = [];
            
            updatePersonalityStatus(personalityType, 'Ready');
            updatePersonalityButton(personalityType, 'Start Conversation', false);
            updatePersonalitySun(personalityType, '');
            
            console.log(`🛑 ${personalityType} conversation stopped`);
        }

        function bufferAudioChunk(personalityType, audioData) {
            const personality = personalities[personalityType];
            
            // Add to buffer
            personality.audioBuffer.push(audioData);
            console.log(`🔊 ${personalityType} buffered chunk ${personality.audioBuffer.length}`);
            
            // Clear existing timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
            }
            
            // If we have enough chunks or timeout, play buffered audio
            if (personality.audioBuffer.length >= 3) {
                flushAudioBuffer(personalityType);
            } else {
                // Set timeout to flush buffer after 500ms
                personality.bufferTimeout = setTimeout(() => {
                    flushAudioBuffer(personalityType);
                }, 500);
            }
        }

        async function flushAudioBuffer(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioBuffer.length === 0) return;
            
            console.log(`🎵 ${personalityType} flushing ${personality.audioBuffer.length} audio chunks`);
            
            // Clear timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            // Play all buffered chunks sequentially
            for (const audioData of personality.audioBuffer) {
                await playAudioChunk(personalityType, audioData);
            }
            
            // Clear buffer
            personality.audioBuffer = [];
            
            // Return to listening state
            updatePersonalityStatus(personalityType, 'Listening...');
            updatePersonalitySun(personalityType, 'listening');
        }

        async function playAudioChunk(personalityType, audioData) {
            // Only play if this personality is currently active
            if (currentActivePersonality !== personalityType) {
                return;
            }

            const personality = personalities[personalityType];
            
            try {
                // Decode base64 audio
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Decode audio buffer
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                
                // Create and schedule audio source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Schedule seamless playback
                const startTime = Math.max(audioContext.currentTime, personality.nextStartTime);
                source.start(startTime);
                
                // Update next start time for seamless playback
                personality.nextStartTime = startTime + audioBuffer.duration;
                
                console.log(`🎵 ${personalityType} audio scheduled seamlessly`);

                // Track current source
                personality.currentSource = source;

            } catch (error) {
                console.error(`❌ ${personalityType} audio playback error:`, error);
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.currentSource) {
                try {
                    personality.currentSource.stop();
                } catch (error) {
                    // Source might already be stopped
                }
                personality.currentSource = null;
            }
            
            personality.audioBuffer = [];
            personality.nextStartTime = 0;
            
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            console.log(`🔇 ${personalityType} audio stopped`);
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (text === 'Stop Conversation') {
                button.classList.add('active');
                button.onclick = () => activatePersonality(personalityType); // This will deactivate since it's already active
            } else {
                button.classList.remove('active');
                button.onclick = () => activatePersonality(personalityType);
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = `sun ${state}`;
        }

        function updatePersonalityCardStates() {
            Object.keys(personalities).forEach(type => {
                const card = document.getElementById(`card-${type}`);
                if (currentActivePersonality === type) {
                    card.classList.add('active');
                    card.classList.remove('inactive');
                } else if (currentActivePersonality) {
                    card.classList.add('inactive');
                    card.classList.remove('active');
                } else {
                    card.classList.remove('active', 'inactive');
                }
            });
            
            if (!currentActivePersonality) {
                updateGlobalStatus('Choose a personality to start conversation');
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        function stopAllConversations() {
            console.log('🛑 Stopping all conversations');
            Object.keys(personalities).forEach(type => {
                if (personalities[type].isConnected) {
                    stopPersonalityConversation(type);
                }
            });
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }
    </script>
</body>
</html>




