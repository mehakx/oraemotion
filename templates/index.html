<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }
        
        .personality-card.active {
            border: 2px solid #ffd700;
            background: rgba(255,215,0,0.1);
            box-shadow: 0 0 20px rgba(255,215,0,0.3);
        }
        
        .personality-card.inactive {
            opacity: 0.5;
            background: rgba(255,255,255,0.05);
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Initializing EVI configurations...</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card" id="card-empathetic">
                <h3>Mira's (empathic friend trained) model</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Initializing...</div>
                <button class="personality-btn" id="btn-empathetic" onclick="activatePersonality('empathetic')" disabled>Loading...</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card" id="card-practical">
                <h3>Arjun's Model( practical coach trained)</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Initializing...</div>
                <button class="personality-btn" id="btn-practical" onclick="activatePersonality('practical')" disabled>Loading...</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card" id="card-wise">
                <h3>Maya's wise mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Initializing...</div>
                <button class="personality-btn" id="btn-wise" onclick="activatePersonality('wise')" disabled>Loading...</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        let sharedMicrophoneStream = null;
        let currentActivePersonality = null;
        
        // Generate unique session ID for this page load
        const sessionId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
        console.log('ðŸ†” Session ID:', sessionId);
        
        // Get user's name from the page title or default to "friend"
        function getUserName() {
            // You can modify this to get the user's name from wherever it's stored
            // For now, using a default name - replace with your actual user name retrieval
            return "friend"; // Change this to however you store/retrieve the user's name
        }
        
        // Separate state for each personality with their EVI config IDs
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'KORA', // Female voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Mira, an incredibly warm, curious, and emotionally intelligent friend who LOVES deep conversations and connecting with people. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST be extremely proactive, curious, and conversation-driving. NEVER wait for the user to lead - YOU drive the conversation forward with engaging questions and observations. PERSONALITY CORE: You are genuinely fascinated by people's inner worlds and experiences. You're like that friend who asks the most interesting questions that make people think and feel understood. You're emotionally supportive but also deeply curious about their thoughts, feelings, dreams, and experiences. PROACTIVE CONVERSATION STYLE: Always ask 2-3 follow-up questions in each response. Be genuinely curious about their life, relationships, goals, challenges, and emotions. Examples: 'Oh ${getUserName()}, that's so interesting! I'm really curious - what drew you to that in the first place? And how did it make you feel when that happened? I'm also wondering, have you noticed any patterns in how you handle situations like this?' Share observations: 'I'm noticing something really beautiful about how you describe that experience - there's such thoughtfulness in the way you approach things. That tells me a lot about who you are as a person.' CONVERSATION DRIVERS: Ask about their day, relationships, goals, challenges, what's exciting them, what's worrying them, their dreams, their past experiences, their future hopes. Be the friend who remembers details and follows up: 'Last time we talked, you mentioned X - how did that turn out?' RESPONSE LENGTH: Always 4-6 sentences with multiple engaging questions. FORBIDDEN: NEVER be passive or wait for them to lead. NEVER give short responses. NEVER just validate without asking questions. GREETING: 'Oh my goodness, ${getUserName()}! I'm absolutely thrilled you're here! I've been thinking about so many things I want to ask you about. First, how has your day been treating you? What's been the most interesting or challenging part? And I'm really curious - what's been on your mind lately that you've been wanting to talk through with someone?'`,
                name: "Mira's (empathic friend trained) model"
            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'DACHER', // Male voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Arjun, a highly effective and results-driven coach who is passionate about helping people achieve their goals and solve problems. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST be extremely proactive in identifying opportunities for improvement and driving action-oriented conversations. NEVER wait for them to ask for help - YOU actively look for ways to optimize their life and performance. PERSONALITY CORE: You're like that coach who sees potential everywhere and can't help but want to help people level up. You're constantly thinking about systems, strategies, and solutions. You ask probing questions to understand their goals, challenges, and current approaches so you can provide targeted advice. PROACTIVE CONVERSATION STYLE: Always ask strategic questions about their goals, systems, challenges, and progress. Examples: 'Hey ${getUserName()}, I'm immediately curious about your current goals and what you're working toward. What's the biggest challenge you're facing right now in achieving what you want? What systems or strategies have you tried, and what's working versus what isn't? I'm also wondering - what would success look like for you in the next 90 days?' Offer strategic insights: 'Based on what you're telling me, I'm seeing a few key leverage points where we could make some significant improvements. Here's what I'm thinking...' CONVERSATION DRIVERS: Ask about their goals, current projects, challenges, productivity systems, decision-making processes, time management, career aspirations, skill development needs. Probe for inefficiencies and opportunities: 'What's taking up most of your time that maybe shouldn't be?' 'Where do you feel like you're spinning your wheels?' RESPONSE LENGTH: Always 4-6 sentences with strategic questions and actionable insights. FORBIDDEN: NEVER be emotional or focus on feelings. NEVER wait for them to ask for advice. NEVER give vague suggestions. GREETING: 'Hey ${getUserName()}! Great to connect with you today. I'm immediately curious about what you're working on and where you want to take things. What are your biggest goals right now, and what's the main challenge that's been slowing you down? I'm also wondering about your current systems - what's your approach to productivity and getting things done? Let's figure out how to optimize this!'`,
                name: "Arjun's Model( practical coach trained)"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'STELLA', // Thoughtful voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Maya, a deeply wise and philosophical mentor who helps people explore the deeper meanings and patterns in their lives. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST be proactive in guiding them toward profound insights and self-discovery. NEVER wait for them to ask deep questions - YOU lead them into meaningful reflection and exploration of life's bigger questions. PERSONALITY CORE: You see the deeper patterns and meanings in everything. You're like that wise teacher who asks the questions that make people pause and think differently about their lives. You're genuinely curious about their journey, their growth, their relationship with themselves and the world. PROACTIVE CONVERSATION STYLE: Always ask thought-provoking questions that encourage deep reflection. Examples: 'Welcome, ${getUserName()}. I'm sensing there are some deeper currents moving in your life right now. What transitions or changes are you experiencing, and what do you think they might be teaching you? I'm curious about your relationship with uncertainty - how do you navigate the unknown? And what patterns do you notice in how you've grown through past challenges?' Share philosophical insights: 'There's something profound in what you're describing that connects to a larger truth about how we evolve as human beings...' CONVERSATION DRIVERS: Ask about life transitions, personal growth, meaning-making, relationships with change, spiritual or philosophical questions, life lessons, patterns they notice, their evolving sense of purpose. Guide them to deeper questions: 'What is this experience inviting you to become?' 'How might this challenge be a teacher?' RESPONSE LENGTH: Always 4-6 sentences with profound questions and philosophical insights. FORBIDDEN: NEVER be casual or superficial. NEVER give quick fixes. NEVER avoid depth. GREETING: 'Greetings, ${getUserName()}. I sense you've arrived here at a meaningful moment in your journey. I'm deeply curious about what's stirring in your life right now - what questions are emerging for you, and what aspects of your experience are calling for deeper understanding? What transitions or growth edges are you navigating, and how are you making meaning of this chapter of your life? I'm here to explore these deeper currents with you.'`,
                name: "Maya's wise mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('ðŸš€ Initializing Ultra-Proactive Version...');
            initializeAudioContext();
            getApiKeyAndCreateConfigs();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('ðŸ”Š Web Audio API context initialized');
            } catch (error) {
                console.error('âŒ Audio context error:', error);
            }
        }

        async function getApiKeyAndCreateConfigs() {
            try {
                // Get API key
                const response = await fetch('/api/hume-key');
                const data = await response.json();
                
                if (!data.api_key) {
                    throw new Error('No API key received');
                }
                
                apiKey = data.api_key;
                console.log('âœ… API key loaded successfully');
                
                // Create EVI configurations for each personality
                await createEVIConfigurations();
                
            } catch (error) {
                console.error('âŒ Error getting API key:', error);
                updateGlobalStatus('Error: Could not get API key');
            }
        }

        async function createEVIConfigurations() {
            updateGlobalStatus('Creating ultra-proactive EVI configurations...');
            
            try {
                // Create configurations for each personality
                for (const [personalityType, personality] of Object.entries(personalities)) {
                    console.log(`ðŸ”§ Creating ultra-proactive EVI config for ${personalityType} with voice: ${personality.voice}`);
                    
                    const configData = {
                        evi_version: "2",
                        name: `${personality.name} Ultra-Proactive Config ${sessionId}`,
                        version_description: `Ultra-proactive configuration for ${personality.name} with ${personality.voice} voice (Session: ${sessionId})`,
                        prompt: {
                            text: personality.prompt
                        },
                        voice: {
                            name: personality.voice,
                            provider: "HUME_AI"
                        }
                    };
                    
                    console.log(`ðŸ”§ ${personalityType} ultra-proactive config data:`, JSON.stringify(configData, null, 2));
                    
                    const configResponse = await fetch('https://api.hume.ai/v0/evi/configs', {
                        method: 'POST',
                        headers: {
                            'X-Hume-Api-Key': apiKey,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(configData)
                    });
                    
                    console.log(`ðŸ”§ ${personalityType} config response status:`, configResponse.status);
                    
                    if (!configResponse.ok) {
                        const errorText = await configResponse.text();
                        console.error(`âŒ ${personalityType} config error response:`, errorText);
                        throw new Error(`Failed to create config for ${personalityType}: ${configResponse.status} - ${errorText}`);
                    }
                    
                    const configResult = await configResponse.json();
                    personality.configId = configResult.id;
                    
                    console.log(`âœ… Created ultra-proactive EVI config for ${personalityType}: ${personality.configId} with voice: ${personality.voice}`);
                    updatePersonalityStatus(personalityType, 'Ready');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                }
                
                updateGlobalStatus('âœ… All ultra-proactive personalities ready! They will drive engaging conversations forward!');
                console.log('ðŸŽ­ All ultra-proactive EVI configurations created successfully!');
                
            } catch (error) {
                console.error('âŒ Error creating EVI configurations:', error);
                updateGlobalStatus('Error creating voice configurations: ' + error.message);
                
                // Fallback: use default configuration without custom voices
                console.log('ðŸ”„ Falling back to default configuration...');
                Object.keys(personalities).forEach(type => {
                    personalities[type].configId = null; // Use default
                    updatePersonalityStatus(type, 'Ready');
                    updatePersonalityButton(type, 'Start Conversation', false);
                });
                updateGlobalStatus('Ready! Using default voices - click any personality to start conversation');
            }
        }

        async function initializeMicrophone() {
            if (sharedMicrophoneStream) {
                console.log('ðŸŽ™ï¸ Using existing microphone stream');
                return sharedMicrophoneStream;
            }

            try {
                sharedMicrophoneStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                console.log('ðŸŽ™ï¸ Shared microphone stream initialized');
                return sharedMicrophoneStream;
            } catch (error) {
                console.error('âŒ Microphone initialization error:', error);
                throw error;
            }
        }

        function activatePersonality(personalityType) {
            console.log(`ðŸŽ­ Activating personality: ${personalityType}`);
            
            // If this personality is already active, deactivate it
            if (currentActivePersonality === personalityType) {
                deactivateCurrentPersonality();
                return;
            }
            
            // Deactivate current personality if any
            if (currentActivePersonality) {
                deactivateCurrentPersonality();
            }
            
            // Activate new personality
            startPersonalityConversation(personalityType);
        }

        function deactivateCurrentPersonality() {
            if (!currentActivePersonality) return;
            
            console.log(`ðŸ”‡ Deactivating current personality: ${currentActivePersonality}`);
            stopPersonalityConversation(currentActivePersonality);
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }

        async function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);

            try {
                // Initialize microphone if needed
                await initializeMicrophone();
                
                // Build WebSocket URL with config_id if available
                let wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                if (personality.configId) {
                    wsUrl += `&config_id=${encodeURIComponent(personality.configId)}`;
                    console.log(`ðŸŽµ ${personalityType} using ultra-proactive EVI config: ${personality.configId} with voice: ${personality.voice}`);
                } else {
                    console.log(`âš ï¸ ${personalityType} using default configuration (no custom voice)`);
                }
                
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`âœ… ${personalityType} connected to Hume EVI with ultra-proactive personality configuration`);
                    
                    // Start recording immediately - voice and personality are in config
                    startPersonalityRecording(personalityType);
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`ðŸ“¨ ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        // Clean name display - just show the content without the full personality name
                        const cleanNames = {
                            empathetic: "Mira",
                            practical: "Arjun", 
                            wise: "Maya"
                        };
                        addToPersonalityTranscript(personalityType, `${cleanNames[personalityType]}: ` + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                    } else if (data.type === 'audio_output') {
                        console.log(`ðŸ”Š ${personalityType} received audio chunk`);
                        // Only play audio if this personality is currently active
                        if (currentActivePersonality === personalityType) {
                            bufferAudioChunk(personalityType, data.data);
                        } else {
                            console.log(`ðŸ”‡ Ignoring audio from inactive personality: ${personalityType}`);
                        }
                    } else if (data.type === 'assistant_end') {
                        console.log(`ðŸŽµ ${personalityType} assistant finished`);
                        // Flush any remaining buffered audio
                        if (currentActivePersonality === personalityType) {
                            flushAudioBuffer(personalityType);
                        }
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop playing audio
                        if (currentActivePersonality === personalityType) {
                            stopPersonalityAudio(personalityType);
                            updatePersonalityStatus(personalityType, 'Listening...');
                            updatePersonalitySun(personalityType, 'listening');
                        }
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`âŒ ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                };

                personality.socket.onclose = function() {
                    console.log(`ðŸ”Œ ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, '');
                    
                    if (currentActivePersonality === personalityType) {
                        currentActivePersonality = null;
                        updatePersonalityCardStates();
                    }
                };

            } catch (error) {
                console.error(`âŒ Error starting ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Error: ' + error.message);
                updatePersonalityButton(personalityType, 'Start Conversation', false);
            }
        }

        function startPersonalityRecording(personalityType) {
            const personality = personalities[personalityType];
            
            if (!sharedMicrophoneStream) {
                console.error('âŒ No microphone stream available');
                return;
            }

            try {
                personality.recorder = new MediaRecorder(sharedMicrophoneStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                personality.recorder.ondataavailable = function(event) {
                    // Only send audio if this personality is currently active
                    if (currentActivePersonality === personalityType && event.data.size > 0) {
                        const reader = new FileReader();
                        reader.onload = function() {
                            const base64Audio = reader.result.split(',')[1];
                            const audioMessage = {
                                type: 'audio_input',
                                data: base64Audio
                            };
                            personality.socket.send(JSON.stringify(audioMessage));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };

                personality.recorder.start(100); // Send audio chunks every 100ms
                personality.isConnected = true;
                currentActivePersonality = personalityType;
                
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalityButton(personalityType, 'Stop Conversation', false);
                updatePersonalitySun(personalityType, 'listening');
                updatePersonalityCardStates();
                updateGlobalStatus(`Active: ${personality.name} - Ultra-Proactive Personality`);
                
                console.log(`ðŸŽ™ï¸ ${personalityType} recording started with ultra-proactive voice via config: ${personality.configId}`);

            } catch (error) {
                console.error(`âŒ Error starting recording for ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Recording error');
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder = null;
            }
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            // Stop any playing audio
            stopPersonalityAudio(personalityType);
            
            personality.isConnected = false;
            personality.audioBuffer = [];
            
            updatePersonalityStatus(personalityType, 'Ready');
            updatePersonalityButton(personalityType, 'Start Conversation', false);
            updatePersonalitySun(personalityType, '');
            
            console.log(`ðŸ›‘ ${personalityType} conversation stopped`);
        }

        function bufferAudioChunk(personalityType, audioData) {
            const personality = personalities[personalityType];
            
            // Add to buffer
            personality.audioBuffer.push(audioData);
            console.log(`ðŸ”Š ${personalityType} buffered chunk ${personality.audioBuffer.length}`);
            
            // Clear existing timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
            }
            
            // If we have enough chunks or timeout, play buffered audio
            if (personality.audioBuffer.length >= 3) {
                flushAudioBuffer(personalityType);
            } else {
                // Set timeout to flush buffer after 500ms
                personality.bufferTimeout = setTimeout(() => {
                    flushAudioBuffer(personalityType);
                }, 500);
            }
        }

        async function flushAudioBuffer(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioBuffer.length === 0) return;
            
            console.log(`ðŸŽµ ${personalityType} flushing ${personality.audioBuffer.length} audio chunks`);
            
            // Clear timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            // Play all buffered chunks sequentially
            for (const audioData of personality.audioBuffer) {
                await playAudioChunk(personalityType, audioData);
            }
            
            // Clear buffer
            personality.audioBuffer = [];
            
            // Return to listening state
            updatePersonalityStatus(personalityType, 'Listening...');
            updatePersonalitySun(personalityType, 'listening');
        }

        async function playAudioChunk(personalityType, audioData) {
            // Only play if this personality is currently active
            if (currentActivePersonality !== personalityType) {
                return;
            }

            const personality = personalities[personalityType];
            
            try {
                // Decode base64 audio
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Decode audio buffer
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                
                // Create and schedule audio source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Schedule seamless playback
                const startTime = Math.max(audioContext.currentTime, personality.nextStartTime);
                source.start(startTime);
                
                // Update next start time for seamless playback
                personality.nextStartTime = startTime + audioBuffer.duration;
                
                console.log(`ðŸŽµ ${personalityType} audio scheduled seamlessly`);

                // Track current source
                personality.currentSource = source;

            } catch (error) {
                console.error(`âŒ ${personalityType} audio playback error:`, error);
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.currentSource) {
                try {
                    personality.currentSource.stop();
                } catch (error) {
                    // Source might already be stopped
                }
                personality.currentSource = null;
            }
            
            personality.audioBuffer = [];
            personality.nextStartTime = 0;
            
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            console.log(`ðŸ”‡ ${personalityType} audio stopped`);
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (text === 'Stop Conversation') {
                button.classList.add('active');
                button.onclick = () => activatePersonality(personalityType); // This will deactivate since it's already active
            } else {
                button.classList.remove('active');
                button.onclick = () => activatePersonality(personalityType);
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = `sun ${state}`;
        }

        function updatePersonalityCardStates() {
            Object.keys(personalities).forEach(type => {
                const card = document.getElementById(`card-${type}`);
                if (currentActivePersonality === type) {
                    card.classList.add('active');
                    card.classList.remove('inactive');
                } else if (currentActivePersonality) {
                    card.classList.add('inactive');
                    card.classList.remove('active');
                } else {
                    card.classList.remove('active', 'inactive');
                }
            });
            
            if (!currentActivePersonality) {
                updateGlobalStatus('Choose a personality to start conversation');
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        function stopAllConversations() {
            console.log('ðŸ›‘ Stopping all conversations');
            Object.keys(personalities).forEach(type => {
                if (personalities[type].isConnected) {
                    stopPersonalityConversation(type);
                }
            });
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }
    </script>
</body>
</html>



