<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Choose a personality to start conversation</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card">
                <h3>Empathetic Friend</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Ready</div>
                <button class="personality-btn" id="btn-empathetic" onclick="togglePersonality('empathetic')">Start Conversation</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card">
                <h3>Practical Coach</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Ready</div>
                <button class="personality-btn" id="btn-practical" onclick="togglePersonality('practical')">Start Conversation</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card">
                <h3>Wise Mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Ready</div>
                <button class="personality-btn" id="btn-wise" onclick="togglePersonality('wise')">Start Conversation</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        
        // Separate state for each personality
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioBuffer: [],
                isCollectingAudio: false,
                audioTimeout: null,
                prompt: "You are a warm, empathetic AI friend named 'The Empathetic Friend'. Listen actively, validate emotions, and provide emotional support. Be understanding, compassionate, and caring. Keep responses conversational and under 2 sentences.",
                name: "The Empathetic Friend"
            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioBuffer: [],
                isCollectingAudio: false,
                audioTimeout: null,
                prompt: "You are a practical, solution-focused AI coach named 'The Practical Coach'. Provide direct, actionable advice and help users solve problems efficiently. Be encouraging but concise and results-oriented. Keep responses brief and under 2 sentences.",
                name: "The Practical Coach"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                currentAudio: null,
                audioBuffer: [],
                isCollectingAudio: false,
                audioTimeout: null,
                prompt: "You are a wise, thoughtful AI mentor named 'The Wise Mentor'. Guide users through reflection and deeper thinking. Ask meaningful questions and share insights. Be thoughtful and philosophical but keep responses under 2 sentences.",
                name: "The Wise Mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('üöÄ Initializing...');
            initializeAudioContext();
            getApiKey();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('üîä Audio context initialized');
            } catch (error) {
                console.error('‚ùå Audio context error:', error);
            }
        }

        function getApiKey() {
            fetch('/api/hume-key')
                .then(response => response.json())
                .then(data => {
                    if (data.api_key) {
                        apiKey = data.api_key;
                        updateGlobalStatus('Ready! Click any personality to start conversation');
                        console.log('‚úÖ API key loaded successfully');
                    } else {
                        throw new Error('No API key received');
                    }
                })
                .catch(error => {
                    console.error('‚ùå Error getting API key:', error);
                    updateGlobalStatus('Error: Could not get API key');
                });
        }

        function togglePersonality(personalityType) {
            const personality = personalities[personalityType];
            
            if (!personality.isConnected) {
                startPersonalityConversation(personalityType);
            } else {
                stopPersonalityConversation(personalityType);
            }
        }

        function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);

            try {
                // Connect to Hume EVI WebSocket
                const wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`‚úÖ ${personalityType} connected to Hume EVI`);
                    updatePersonalityStatus(personalityType, 'Connected! Starting microphone...');
                    
                    // Send personality prompt
                    const systemMessage = {
                        type: 'session_settings',
                        system_prompt: personality.prompt + " The user's name is User. Greet them warmly and introduce yourself as " + personality.name + ".",
                        language: 'en'
                    };
                    personality.socket.send(JSON.stringify(systemMessage));
                    
                    startPersonalityMicrophone(personalityType);
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`üì® ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        addToPersonalityTranscript(personalityType, 'AI: ' + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                        
                        // Start collecting audio for this response
                        personality.audioBuffer = [];
                        personality.isCollectingAudio = true;
                        console.log(`üéµ ${personalityType} started collecting audio for response`);
                        
                        // Set timeout to play buffered audio
                        if (personality.audioTimeout) clearTimeout(personality.audioTimeout);
                        personality.audioTimeout = setTimeout(() => {
                            console.log(`‚è∞ ${personalityType} timeout - playing buffered audio`);
                            playBufferedAudio(personalityType);
                        }, 2000); // 2 second timeout
                        
                    } else if (data.type === 'audio_output') {
                        console.log(`üîä ${personalityType} received audio chunk`);
                        
                        if (personality.isCollectingAudio) {
                            // Buffer this audio chunk
                            personality.audioBuffer.push(data.data);
                            console.log(`üì¶ ${personalityType} buffered chunk ${personality.audioBuffer.length}`);
                            
                            // If we have enough chunks, play the buffered audio
                            if (personality.audioBuffer.length >= 5) {
                                console.log(`üéµ ${personalityType} has enough chunks - playing buffered audio`);
                                playBufferedAudio(personalityType);
                            }
                        }
                        
                    } else if (data.type === 'assistant_end') {
                        console.log(`üéµ ${personalityType} assistant finished - playing final buffered audio`);
                        playBufferedAudio(personalityType);
                        
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop collecting and playing audio
                        personality.isCollectingAudio = false;
                        personality.audioBuffer = [];
                        if (personality.audioTimeout) clearTimeout(personality.audioTimeout);
                        stopPersonalityAudio(personalityType);
                        updatePersonalityStatus(personalityType, 'Listening...');
                        updatePersonalitySun(personalityType, 'listening');
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`‚ùå ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                };

                personality.socket.onclose = function() {
                    console.log(`üîå ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, 'idle');
                    personality.isConnected = false;
                };

            } catch (error) {
                console.error(`‚ùå Error starting ${personalityType} conversation:`, error);
                updatePersonalityStatus(personalityType, 'Error starting conversation');
                updatePersonalityButton(personalityType, 'Start Conversation', false);
            }
        }

        function startPersonalityMicrophone(personalityType) {
            const personality = personalities[personalityType];
            
            navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            })
                .then(function(stream) {
                    console.log(`üéôÔ∏è ${personalityType} microphone access granted`);
                    
                    personality.recorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    personality.recorder.ondataavailable = function(event) {
                        if (event.data.size > 0 && personality.socket && personality.socket.readyState === WebSocket.OPEN) {
                            const reader = new FileReader();
                            reader.onloadend = function() {
                                const base64Audio = reader.result.split(',')[1];
                                personality.socket.send(JSON.stringify({
                                    type: 'audio_input',
                                    data: base64Audio
                                }));
                            };
                            reader.readAsDataURL(event.data);
                        }
                    };

                    personality.recorder.start(100); // Send audio every 100ms
                    
                    personality.isConnected = true;
                    updatePersonalityStatus(personalityType, 'Listening...');
                    updatePersonalitySun(personalityType, 'listening');
                    updatePersonalityButton(personalityType, 'Stop Conversation', false);
                    
                    console.log(`üé§ ${personalityType} recording started`);
                })
                .catch(function(error) {
                    console.error(`‚ùå ${personalityType} microphone error:`, error);
                    updatePersonalityStatus(personalityType, 'Microphone access denied');
                    if (personality.socket) personality.socket.close();
                });
        }

        function playBufferedAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioBuffer.length === 0) {
                console.log(`‚ö†Ô∏è ${personalityType} no audio chunks to play`);
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalitySun(personalityType, 'listening');
                return;
            }
            
            console.log(`üéµ ${personalityType} playing buffered audio from ${personality.audioBuffer.length} chunks`);
            
            // Stop collecting
            personality.isCollectingAudio = false;
            if (personality.audioTimeout) clearTimeout(personality.audioTimeout);
            
            // Stop any current audio first
            stopPersonalityAudio(personalityType);
            
            try {
                // Combine all buffered chunks into one audio stream
                let combinedBase64 = '';
                personality.audioBuffer.forEach(chunk => {
                    combinedBase64 += chunk;
                });
                
                // Decode combined base64 audio
                const binaryString = atob(combinedBase64);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                
                const audioBlob = new Blob([bytes], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                
                personality.currentAudio = new Audio();
                
                personality.currentAudio.oncanplaythrough = function() {
                    console.log(`üîä ${personalityType} combined audio ready to play`);
                    personality.currentAudio.play().catch(error => {
                        console.error(`‚ùå ${personalityType} audio play error:`, error);
                        updatePersonalityStatus(personalityType, 'Listening...');
                        updatePersonalitySun(personalityType, 'listening');
                    });
                };
                
                personality.currentAudio.onplay = function() {
                    console.log(`üîä ${personalityType} smooth audio playback started`);
                };
                
                personality.currentAudio.onended = function() {
                    console.log(`üîä ${personalityType} smooth audio playback ended`);
                    URL.revokeObjectURL(audioUrl);
                    personality.currentAudio = null;
                    updatePersonalityStatus(personalityType, 'Listening...');
                    updatePersonalitySun(personalityType, 'listening');
                };
                
                personality.currentAudio.onerror = function(error) {
                    console.error(`‚ùå ${personalityType} audio error:`, error);
                    URL.revokeObjectURL(audioUrl);
                    personality.currentAudio = null;
                    updatePersonalityStatus(personalityType, 'Listening...');
                    updatePersonalitySun(personalityType, 'listening');
                };
                
                personality.currentAudio.src = audioUrl;
                personality.currentAudio.load();
                
                // Clear buffer
                personality.audioBuffer = [];
                
            } catch (error) {
                console.error(`‚ùå Error playing ${personalityType} buffered audio:`, error);
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalitySun(personalityType, 'listening');
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.currentAudio) {
                personality.currentAudio.pause();
                personality.currentAudio.currentTime = 0;
                personality.currentAudio = null;
                console.log(`üîá ${personalityType} audio stopped`);
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            console.log(`üîö Stopping ${personalityType} conversation`);
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder.stream.getTracks().forEach(track => track.stop());
                personality.recorder = null;
            }
            
            stopPersonalityAudio(personalityType);
            personality.isCollectingAudio = false;
            personality.audioBuffer = [];
            if (personality.audioTimeout) clearTimeout(personality.audioTimeout);
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            personality.isConnected = false;
            updatePersonalityStatus(personalityType, 'Conversation stopped');
            updatePersonalitySun(personalityType, 'idle');
            updatePersonalityButton(personalityType, 'Start Conversation', false);
        }

        function stopAllConversations() {
            console.log('üîö Stopping all conversations');
            Object.keys(personalities).forEach(personalityType => {
                if (personalities[personalityType].isConnected) {
                    stopPersonalityConversation(personalityType);
                }
            });
            updateGlobalStatus('All conversations stopped');
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
            console.log('üìä Global Status:', message);
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
            console.log(`üìä ${personalityType} Status:`, message);
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (personalities[personalityType].isConnected) {
                button.classList.add('active');
            } else {
                button.classList.remove('active');
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = 'sun';
            if (state !== 'idle') {
                sun.classList.add(state);
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        // Handle page unload
        window.addEventListener('beforeunload', function() {
            stopAllConversations();
        });

        // Handle user interaction for audio context
        document.addEventListener('click', function() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume();
                console.log('üîä Audio context resumed');
            }
        });
    </script>
</body>
</html>


