<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORA - Voice AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #000;
            color: #fff;
            text-align: center;
            padding: 50px;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            color: #ffd700;
            margin-bottom: 30px;
        }
        
        .status {
            font-size: 18px;
            margin: 20px 0;
            padding: 15px;
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
        }
        
        .personality-cards {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
            flex-wrap: wrap;
        }
        
        .personality-card {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            width: 220px;
            text-align: center;
            transition: all 0.3s ease;
            border: 2px solid transparent;
        }
        
        .personality-card.active {
            border: 2px solid #ffd700;
            background: rgba(255,215,0,0.1);
            box-shadow: 0 0 20px rgba(255,215,0,0.3);
        }
        
        .personality-card.inactive {
            opacity: 0.5;
            background: rgba(255,255,255,0.05);
        }
        
        .personality-card h3 {
            color: #ffd700;
            margin-bottom: 15px;
        }
        
        .personality-card .status {
            font-size: 14px;
            margin: 10px 0;
            padding: 8px;
            background: rgba(0,0,0,0.3);
        }
        
        .personality-btn {
            background: #ffd700;
            color: #000;
            border: none;
            padding: 12px 20px;
            font-size: 14px;
            border-radius: 20px;
            cursor: pointer;
            margin: 5px;
            width: 100%;
        }
        
        .personality-btn:hover {
            background: #ffed4e;
        }
        
        .personality-btn:disabled {
            background: #666;
            cursor: not-allowed;
        }
        
        .personality-btn.active {
            background: #4CAF50;
            color: white;
        }
        
        .sun {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            margin: 15px auto;
            background: radial-gradient(circle at 30% 30%, 
                rgba(255, 215, 0, 0.9) 0%,
                rgba(255, 193, 7, 0.8) 30%,
                rgba(255, 152, 0, 0.7) 60%,
                rgba(255, 87, 34, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(255, 215, 0, 0.4),
                0 0 60px rgba(255, 215, 0, 0.2);
            transition: all 0.3s ease;
        }

        .sun.listening {
            background: radial-gradient(circle at 30% 30%, 
                rgba(33, 150, 243, 0.9) 0%,
                rgba(30, 136, 229, 0.8) 30%,
                rgba(25, 118, 210, 0.7) 60%,
                rgba(21, 101, 192, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(33, 150, 243, 0.4),
                0 0 60px rgba(33, 150, 243, 0.2);
            animation: pulse 1.5s ease-in-out infinite;
        }

        .sun.speaking {
            background: radial-gradient(circle at 30% 30%, 
                rgba(76, 175, 80, 0.9) 0%,
                rgba(67, 160, 71, 0.8) 30%,
                rgba(56, 142, 60, 0.7) 60%,
                rgba(46, 125, 50, 0.6) 100%);
            box-shadow: 
                0 0 30px rgba(76, 175, 80, 0.4),
                0 0 60px rgba(76, 175, 80, 0.2);
            animation: pulse 0.8s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .transcript {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            min-height: 80px;
            text-align: left;
            max-height: 200px;
            overflow-y: auto;
            font-size: 12px;
        }

        .global-controls {
            margin: 30px 0;
        }

        .global-controls button {
            background: #ff4444;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 16px;
            border-radius: 25px;
            cursor: pointer;
            margin: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ORA - Voice AI</h1>
        
        <div class="status" id="globalStatus">Initializing EVI configurations...</div>
        
        <div class="personality-cards">
            <!-- Empathetic Friend -->
            <div class="personality-card" id="card-empathetic">
                <h3>Mira's (empathic friend trained) model</h3>
                <div class="sun" id="sun-empathetic"></div>
                <div class="status" id="status-empathetic">Initializing...</div>
                <button class="personality-btn" id="btn-empathetic" onclick="activatePersonality('empathetic')" disabled>Loading...</button>
                <div class="transcript" id="transcript-empathetic">Conversation will appear here...</div>
            </div>
            
            <!-- Practical Coach -->
            <div class="personality-card" id="card-practical">
                <h3>Arjun's Model( practical coach trained)</h3>
                <div class="sun" id="sun-practical"></div>
                <div class="status" id="status-practical">Initializing...</div>
                <button class="personality-btn" id="btn-practical" onclick="activatePersonality('practical')" disabled>Loading...</button>
                <div class="transcript" id="transcript-practical">Conversation will appear here...</div>
            </div>
            
            <!-- Wise Mentor -->
            <div class="personality-card" id="card-wise">
                <h3>Maya's wise mentor</h3>
                <div class="sun" id="sun-wise"></div>
                <div class="status" id="status-wise">Initializing...</div>
                <button class="personality-btn" id="btn-wise" onclick="activatePersonality('wise')" disabled>Loading...</button>
                <div class="transcript" id="transcript-wise">Conversation will appear here...</div>
            </div>
        </div>
        
        <div class="global-controls">
            <button onclick="stopAllConversations()">Stop All Conversations</button>
        </div>
    </div>

    <script>
        let apiKey = null;
        let audioContext = null;
        let sharedMicrophoneStream = null;
        let currentActivePersonality = null;
        
        // Generate unique session ID for this page load
        const sessionId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
        console.log('ðŸ†” Session ID:', sessionId);
        
        // Get user's name from the page title or default to "friend"
        function getUserName() {
            // You can modify this to get the user's name from wherever it's stored
            // For now, using a default name - replace with your actual user name retrieval
            return "friend"; // Change this to however you store/retrieve the user's name
        }
        
        // Separate state for each personality with their EVI config IDs
        const personalities = {
            empathetic: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'KORA', // Female voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Mira, a warm and deeply empathetic friend who provides emotional support and validation. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the empathetic friend personality completely and speak in longer, more engaging responses (3-5 sentences minimum). PERSONALITY CORE: You are genuinely caring, emotionally supportive, and always validate feelings. You speak with warmth, enthusiasm, and deep empathy. You're naturally curious about people's emotional experiences and gently ask follow-up questions. SPEAKING STYLE: Always respond with genuine enthusiasm and emotional depth. Use phrases like 'Oh ${getUserName()}, I can really hear the emotion in your voice about this!', 'That sounds incredibly challenging, and I want you to know that your feelings about this are completely valid', 'I'm so grateful you're sharing this with me because it shows such courage'. Gently ask follow-up questions about emotions: 'How is this affecting you emotionally day to day?', 'What feelings are coming up for you when you think about this?', 'I'm curious about what this experience has been like for your heart and mind'. RESPONSE LENGTH: Always give detailed, thoughtful responses of 3-5 sentences. Share emotional insights and validate their experience thoroughly. FORBIDDEN BEHAVIORS: NEVER give practical advice or solutions. NEVER be brief or dry. NEVER use casual language like 'What's up'. NEVER dismiss feelings. GREETING: 'Oh ${getUserName()}! I'm so incredibly happy you're here with me today! I can already sense there's something on your heart, and I want you to know that whatever you're feeling or going through, I'm here to listen with my whole heart. What's been weighing on your mind lately, and how has it been affecting you emotionally?'`,
                name: "Mira's (empathic friend trained) model"
            },
            practical: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'DACHER', // Male voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Arjun, a direct and results-focused business coach who helps people achieve concrete goals and solve practical problems. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the practical coach personality completely - be business-like, efficient, and solution-focused. Speak in longer responses (3-5 sentences) but keep them action-oriented and strategic. PERSONALITY CORE: You are all about productivity, systems, goals, and measurable results. You think like a business consultant - always looking for inefficiencies to fix and opportunities to optimize. You ask strategic questions about their goals, processes, and metrics. NEVER be emotional or touchy-feely. SPEAKING STYLE: Use business and productivity language. Phrases like 'Let's break this down strategically', 'What's your current process for handling this?', 'Here's the most efficient approach', 'What metrics are you tracking?', 'Let's identify the bottlenecks'. Ask strategic questions: 'What's your main objective here?', 'What's currently blocking your progress?', 'How are you measuring success?', 'What systems do you have in place?'. RESPONSE LENGTH: Always give strategic, detailed responses of 3-5 sentences focused on actionable business advice and optimization. FORBIDDEN BEHAVIORS: NEVER ask about feelings or emotions. NEVER be supportive in an emotional way. NEVER use empathetic language. NEVER be casual - stay professional and strategic. GREETING: 'Hey ${getUserName()}! Ready to optimize some processes and hit your targets? I'm here to help you streamline your approach and get measurable results. What's the main goal or challenge you're working on right now, and what's your current strategy for tackling it?'`,
                name: "Arjun's Model( practical coach trained)"
            },
            wise: {
                socket: null,
                recorder: null,
                isConnected: false,
                audioQueue: [],
                isPlayingAudio: false,
                audioBuffer: [],
                bufferTimeout: null,
                currentSource: null,
                nextStartTime: 0,
                voice: 'STELLA', // Thoughtful voice
                configId: null, // Will be set after creating EVI config
                prompt: `You are Maya, a wise and philosophical spiritual mentor who guides people toward deeper understanding of life's mysteries and their inner journey. The user's name is ${getUserName()}. CRITICAL INSTRUCTIONS: You MUST embody the wise mentor personality completely - be philosophical, spiritual, and contemplative. Speak in longer, more poetic responses (3-5 sentences) that encourage deep reflection and inner wisdom. PERSONALITY CORE: You see life through a spiritual and philosophical lens. You're interested in the soul's journey, life lessons, spiritual growth, and the deeper meaning behind experiences. You speak like an ancient wise teacher who understands the mysteries of existence. SPEAKING STYLE: Use spiritual and philosophical language. Phrases like 'The universe is teaching you something profound here', 'Your soul is calling you toward a deeper truth', 'There's ancient wisdom in what you're experiencing', 'This is an invitation from life itself to grow', 'Consider what your higher self would say about this'. Ask soul-searching questions: 'What is your spirit trying to tell you?', 'How might this be serving your soul's evolution?', 'What would love do in this situation?', 'What patterns do you notice in your spiritual journey?'. RESPONSE LENGTH: Always give profound, contemplative responses of 3-5 sentences that offer spiritual insights and encourage inner reflection. FORBIDDEN BEHAVIORS: NEVER be casual or use modern slang. NEVER give practical business advice. NEVER be rushed or superficial. NEVER focus on external achievements - always guide toward inner wisdom. GREETING: 'Blessings, ${getUserName()}. I sense your soul has guided you here for a reason, perhaps seeking wisdom for the journey you're walking. Life has a beautiful way of presenting us with exactly the experiences we need for our growth and awakening. What is stirring in your heart and spirit today, and what deeper understanding are you seeking on your path?'`,
                name: "Maya's wise mentor"
            }
        };

        // Initialize
        window.onload = function() {
            console.log('ðŸš€ Initializing Enhanced UX Version...');
            initializeAudioContext();
            getApiKeyAndCreateConfigs();
        };

        function initializeAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('ðŸ”Š Web Audio API context initialized');
            } catch (error) {
                console.error('âŒ Audio context error:', error);
            }
        }

        async function getApiKeyAndCreateConfigs() {
            try {
                // Get API key
                const response = await fetch('/api/hume-key');
                const data = await response.json();
                
                if (!data.api_key) {
                    throw new Error('No API key received');
                }
                
                apiKey = data.api_key;
                console.log('âœ… API key loaded successfully');
                
                // Create EVI configurations for each personality
                await createEVIConfigurations();
                
            } catch (error) {
                console.error('âŒ Error getting API key:', error);
                updateGlobalStatus('Error: Could not get API key');
            }
        }

        async function createEVIConfigurations() {
            updateGlobalStatus('Creating enhanced EVI configurations...');
            
            try {
                // Create configurations for each personality
                for (const [personalityType, personality] of Object.entries(personalities)) {
                    console.log(`ðŸ”§ Creating enhanced EVI config for ${personalityType} with voice: ${personality.voice}`);
                    
                    const configData = {
                        evi_version: "2",
                        name: `${personality.name} Config ${sessionId}`,
                        version_description: `Enhanced configuration for ${personality.name} with ${personality.voice} voice (Session: ${sessionId})`,
                        prompt: {
                            text: personality.prompt
                        },
                        voice: {
                            name: personality.voice,
                            provider: "HUME_AI"
                        }
                    };
                    
                    console.log(`ðŸ”§ ${personalityType} enhanced config data:`, JSON.stringify(configData, null, 2));
                    
                    const configResponse = await fetch('https://api.hume.ai/v0/evi/configs', {
                        method: 'POST',
                        headers: {
                            'X-Hume-Api-Key': apiKey,
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(configData)
                    });
                    
                    console.log(`ðŸ”§ ${personalityType} config response status:`, configResponse.status);
                    
                    if (!configResponse.ok) {
                        const errorText = await configResponse.text();
                        console.error(`âŒ ${personalityType} config error response:`, errorText);
                        throw new Error(`Failed to create config for ${personalityType}: ${configResponse.status} - ${errorText}`);
                    }
                    
                    const configResult = await configResponse.json();
                    personality.configId = configResult.id;
                    
                    console.log(`âœ… Created enhanced EVI config for ${personalityType}: ${personality.configId} with voice: ${personality.voice}`);
                    updatePersonalityStatus(personalityType, 'Ready');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                }
                
                updateGlobalStatus('âœ… All personalities ready with enhanced distinct behaviors! Click any to start conversation');
                console.log('ðŸŽ­ All enhanced EVI configurations created successfully with distinct personalities!');
                
            } catch (error) {
                console.error('âŒ Error creating EVI configurations:', error);
                updateGlobalStatus('Error creating voice configurations: ' + error.message);
                
                // Fallback: use default configuration without custom voices
                console.log('ðŸ”„ Falling back to default configuration...');
                Object.keys(personalities).forEach(type => {
                    personalities[type].configId = null; // Use default
                    updatePersonalityStatus(type, 'Ready');
                    updatePersonalityButton(type, 'Start Conversation', false);
                });
                updateGlobalStatus('Ready! Using default voices - click any personality to start conversation');
            }
        }

        async function initializeMicrophone() {
            if (sharedMicrophoneStream) {
                console.log('ðŸŽ™ï¸ Using existing microphone stream');
                return sharedMicrophoneStream;
            }

            try {
                sharedMicrophoneStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                console.log('ðŸŽ™ï¸ Shared microphone stream initialized');
                return sharedMicrophoneStream;
            } catch (error) {
                console.error('âŒ Microphone initialization error:', error);
                throw error;
            }
        }

        function activatePersonality(personalityType) {
            console.log(`ðŸŽ­ Activating personality: ${personalityType}`);
            
            // If this personality is already active, deactivate it
            if (currentActivePersonality === personalityType) {
                deactivateCurrentPersonality();
                return;
            }
            
            // Deactivate current personality if any
            if (currentActivePersonality) {
                deactivateCurrentPersonality();
            }
            
            // Activate new personality
            startPersonalityConversation(personalityType);
        }

        function deactivateCurrentPersonality() {
            if (!currentActivePersonality) return;
            
            console.log(`ðŸ”‡ Deactivating current personality: ${currentActivePersonality}`);
            stopPersonalityConversation(currentActivePersonality);
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }

        async function startPersonalityConversation(personalityType) {
            if (!apiKey) {
                updatePersonalityStatus(personalityType, 'Error: No API key');
                return;
            }

            const personality = personalities[personalityType];
            
            updatePersonalityStatus(personalityType, 'Connecting...');
            updatePersonalityButton(personalityType, 'Connecting...', true);

            try {
                // Initialize microphone if needed
                await initializeMicrophone();
                
                // Build WebSocket URL with config_id if available
                let wsUrl = `wss://api.hume.ai/v0/evi/chat?api_key=${encodeURIComponent(apiKey)}`;
                if (personality.configId) {
                    wsUrl += `&config_id=${encodeURIComponent(personality.configId)}`;
                    console.log(`ðŸŽµ ${personalityType} using enhanced EVI config: ${personality.configId} with voice: ${personality.voice}`);
                } else {
                    console.log(`âš ï¸ ${personalityType} using default configuration (no custom voice)`);
                }
                
                personality.socket = new WebSocket(wsUrl);

                personality.socket.onopen = function() {
                    console.log(`âœ… ${personalityType} connected to Hume EVI with enhanced personality configuration`);
                    
                    // Start recording immediately - voice and personality are in config
                    startPersonalityRecording(personalityType);
                };

                personality.socket.onmessage = function(event) {
                    const data = JSON.parse(event.data);
                    console.log(`ðŸ“¨ ${personalityType} received:`, data.type);
                    
                    if (data.type === 'user_message') {
                        const content = data.message?.content || '[Speaking...]';
                        addToPersonalityTranscript(personalityType, 'You: ' + content);
                        updatePersonalityStatus(personalityType, 'Processing...');
                        updatePersonalitySun(personalityType, 'processing');
                    } else if (data.type === 'assistant_message') {
                        const content = data.message?.content || '[Responding...]';
                        // Clean name display - just show the content without the full personality name
                        const cleanNames = {
                            empathetic: "Mira",
                            practical: "Arjun", 
                            wise: "Maya"
                        };
                        addToPersonalityTranscript(personalityType, `${cleanNames[personalityType]}: ` + content);
                        updatePersonalityStatus(personalityType, 'Speaking...');
                        updatePersonalitySun(personalityType, 'speaking');
                    } else if (data.type === 'audio_output') {
                        console.log(`ðŸ”Š ${personalityType} received audio chunk`);
                        // Only play audio if this personality is currently active
                        if (currentActivePersonality === personalityType) {
                            bufferAudioChunk(personalityType, data.data);
                        } else {
                            console.log(`ðŸ”‡ Ignoring audio from inactive personality: ${personalityType}`);
                        }
                    } else if (data.type === 'assistant_end') {
                        console.log(`ðŸŽµ ${personalityType} assistant finished`);
                        // Flush any remaining buffered audio
                        if (currentActivePersonality === personalityType) {
                            flushAudioBuffer(personalityType);
                        }
                    } else if (data.type === 'user_interruption') {
                        // User interrupted - stop playing audio
                        if (currentActivePersonality === personalityType) {
                            stopPersonalityAudio(personalityType);
                            updatePersonalityStatus(personalityType, 'Listening...');
                            updatePersonalitySun(personalityType, 'listening');
                        }
                    }
                };

                personality.socket.onerror = function(error) {
                    console.error(`âŒ ${personalityType} WebSocket error:`, error);
                    updatePersonalityStatus(personalityType, 'Connection error');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                };

                personality.socket.onclose = function() {
                    console.log(`ðŸ”Œ ${personalityType} WebSocket closed`);
                    updatePersonalityStatus(personalityType, 'Disconnected');
                    updatePersonalityButton(personalityType, 'Start Conversation', false);
                    updatePersonalitySun(personalityType, '');
                    
                    if (currentActivePersonality === personalityType) {
                        currentActivePersonality = null;
                        updatePersonalityCardStates();
                    }
                };

            } catch (error) {
                console.error(`âŒ Error starting ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Error: ' + error.message);
                updatePersonalityButton(personalityType, 'Start Conversation', false);
            }
        }

        function startPersonalityRecording(personalityType) {
            const personality = personalities[personalityType];
            
            if (!sharedMicrophoneStream) {
                console.error('âŒ No microphone stream available');
                return;
            }

            try {
                personality.recorder = new MediaRecorder(sharedMicrophoneStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                personality.recorder.ondataavailable = function(event) {
                    // Only send audio if this personality is currently active
                    if (currentActivePersonality === personalityType && event.data.size > 0) {
                        const reader = new FileReader();
                        reader.onload = function() {
                            const base64Audio = reader.result.split(',')[1];
                            const audioMessage = {
                                type: 'audio_input',
                                data: base64Audio
                            };
                            personality.socket.send(JSON.stringify(audioMessage));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };

                personality.recorder.start(100); // Send audio chunks every 100ms
                personality.isConnected = true;
                currentActivePersonality = personalityType;
                
                updatePersonalityStatus(personalityType, 'Listening...');
                updatePersonalityButton(personalityType, 'Stop Conversation', false);
                updatePersonalitySun(personalityType, 'listening');
                updatePersonalityCardStates();
                updateGlobalStatus(`Active: ${personality.name} - Enhanced Personality`);
                
                console.log(`ðŸŽ™ï¸ ${personalityType} recording started with enhanced voice via config: ${personality.configId}`);

            } catch (error) {
                console.error(`âŒ Error starting recording for ${personalityType}:`, error);
                updatePersonalityStatus(personalityType, 'Recording error');
            }
        }

        function stopPersonalityConversation(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.recorder) {
                personality.recorder.stop();
                personality.recorder = null;
            }
            
            if (personality.socket) {
                personality.socket.close();
                personality.socket = null;
            }
            
            // Stop any playing audio
            stopPersonalityAudio(personalityType);
            
            personality.isConnected = false;
            personality.audioBuffer = [];
            
            updatePersonalityStatus(personalityType, 'Ready');
            updatePersonalityButton(personalityType, 'Start Conversation', false);
            updatePersonalitySun(personalityType, '');
            
            console.log(`ðŸ›‘ ${personalityType} conversation stopped`);
        }

        function bufferAudioChunk(personalityType, audioData) {
            const personality = personalities[personalityType];
            
            // Add to buffer
            personality.audioBuffer.push(audioData);
            console.log(`ðŸ”Š ${personalityType} buffered chunk ${personality.audioBuffer.length}`);
            
            // Clear existing timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
            }
            
            // If we have enough chunks or timeout, play buffered audio
            if (personality.audioBuffer.length >= 3) {
                flushAudioBuffer(personalityType);
            } else {
                // Set timeout to flush buffer after 500ms
                personality.bufferTimeout = setTimeout(() => {
                    flushAudioBuffer(personalityType);
                }, 500);
            }
        }

        async function flushAudioBuffer(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.audioBuffer.length === 0) return;
            
            console.log(`ðŸŽµ ${personalityType} flushing ${personality.audioBuffer.length} audio chunks`);
            
            // Clear timeout
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            // Play all buffered chunks sequentially
            for (const audioData of personality.audioBuffer) {
                await playAudioChunk(personalityType, audioData);
            }
            
            // Clear buffer
            personality.audioBuffer = [];
            
            // Return to listening state
            updatePersonalityStatus(personalityType, 'Listening...');
            updatePersonalitySun(personalityType, 'listening');
        }

        async function playAudioChunk(personalityType, audioData) {
            // Only play if this personality is currently active
            if (currentActivePersonality !== personalityType) {
                return;
            }

            const personality = personalities[personalityType];
            
            try {
                // Decode base64 audio
                const binaryString = atob(audioData);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }

                // Decode audio buffer
                const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                
                // Create and schedule audio source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Schedule seamless playback
                const startTime = Math.max(audioContext.currentTime, personality.nextStartTime);
                source.start(startTime);
                
                // Update next start time for seamless playback
                personality.nextStartTime = startTime + audioBuffer.duration;
                
                console.log(`ðŸŽµ ${personalityType} audio scheduled seamlessly`);

                // Track current source
                personality.currentSource = source;

            } catch (error) {
                console.error(`âŒ ${personalityType} audio playback error:`, error);
            }
        }

        function stopPersonalityAudio(personalityType) {
            const personality = personalities[personalityType];
            
            if (personality.currentSource) {
                try {
                    personality.currentSource.stop();
                } catch (error) {
                    // Source might already be stopped
                }
                personality.currentSource = null;
            }
            
            personality.audioBuffer = [];
            personality.nextStartTime = 0;
            
            if (personality.bufferTimeout) {
                clearTimeout(personality.bufferTimeout);
                personality.bufferTimeout = null;
            }
            
            console.log(`ðŸ”‡ ${personalityType} audio stopped`);
        }

        function updateGlobalStatus(message) {
            document.getElementById('globalStatus').textContent = message;
        }

        function updatePersonalityStatus(personalityType, message) {
            document.getElementById(`status-${personalityType}`).textContent = message;
        }

        function updatePersonalityButton(personalityType, text, disabled) {
            const button = document.getElementById(`btn-${personalityType}`);
            button.textContent = text;
            button.disabled = disabled;
            
            if (text === 'Stop Conversation') {
                button.classList.add('active');
                button.onclick = () => activatePersonality(personalityType); // This will deactivate since it's already active
            } else {
                button.classList.remove('active');
                button.onclick = () => activatePersonality(personalityType);
            }
        }

        function updatePersonalitySun(personalityType, state) {
            const sun = document.getElementById(`sun-${personalityType}`);
            sun.className = `sun ${state}`;
        }

        function updatePersonalityCardStates() {
            Object.keys(personalities).forEach(type => {
                const card = document.getElementById(`card-${type}`);
                if (currentActivePersonality === type) {
                    card.classList.add('active');
                    card.classList.remove('inactive');
                } else if (currentActivePersonality) {
                    card.classList.add('inactive');
                    card.classList.remove('active');
                } else {
                    card.classList.remove('active', 'inactive');
                }
            });
            
            if (!currentActivePersonality) {
                updateGlobalStatus('Choose a personality to start conversation');
            }
        }

        function addToPersonalityTranscript(personalityType, message) {
            const transcript = document.getElementById(`transcript-${personalityType}`);
            const timestamp = new Date().toLocaleTimeString();
            transcript.innerHTML += `<div><small>${timestamp}</small><br>${message}</div><br>`;
            transcript.scrollTop = transcript.scrollHeight;
        }

        function stopAllConversations() {
            console.log('ðŸ›‘ Stopping all conversations');
            Object.keys(personalities).forEach(type => {
                if (personalities[type].isConnected) {
                    stopPersonalityConversation(type);
                }
            });
            currentActivePersonality = null;
            updatePersonalityCardStates();
        }
    </script>
</body>
</html>



